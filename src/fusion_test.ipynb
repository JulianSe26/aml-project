{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60af1d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detection_fusion import detection_fusion\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rcnn.dataset import ChestCocoDetection\n",
    "from torchvision import transforms\n",
    "import matplotlib.patches as patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffecaa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bounding_boxes(target, ax):\n",
    "    boxes = target['boxes']\n",
    "    for box in boxes:\n",
    "        mp_box = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1], edgecolor=\"r\", facecolor='none')\n",
    "        ax.add_patch(mp_box)\n",
    "\n",
    "def show_samples_for(test, train):\n",
    "    print(test[1])\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,8))\n",
    "    #fig.suptitle(f'Study: {samples[\"id\"].iloc[i]}')\n",
    "    for im_i, (img, data) in enumerate([test, train]):\n",
    "        ax = axs[im_i] if isinstance(axs, np.ndarray) else axs\n",
    "        ax.set_title(f'Instance / Image Nr. {im_i + 1} / {2}')\n",
    "        #dcm = pydicom.dcmread(image_path)\n",
    "        plt.figure()\n",
    "        ax.imshow(img.permute(1,2,0), cmap=plt.cm.bone)\n",
    "        add_bounding_boxes(data, ax)\n",
    "    fig.savefig(\"combo.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d89adcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "test = ChestCocoDetection(root=\"F:\\\\aml-project\\data\\\\siim-covid19-detection\", ann_file=\"F:\\\\aml-project\\\\data\\\\siim-covid19-detection\\\\test.json\", training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "642b7530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([3, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(test))\n",
    "test_img = test.__getitem__(idx)\n",
    "print(type(test_img[0]), test_img[0].shape)\n",
    "img = test_img[0].detach()\n",
    "img_pil = transforms.ToPILImage()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "505bce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\aml\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "results, boxes, scores = detection_fusion(img_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcf7422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': tensor([4446]), 'boxes': tensor([[726.46149, 129.70667, 964.14136, 672.42670]]), 'area': tensor([128993.60938]), 'labels': tensor([1]), 'size': tensor([4248, 3480], dtype=torch.int16)}\n"
     ]
    }
   ],
   "source": [
    "show_samples_for(test_img, (test_img[0], {\"boxes\":boxes}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04317aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

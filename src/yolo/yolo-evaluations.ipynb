{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO pretraining on RSNA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_path = \"./losses_giou_pretrained_100/\"\n",
    "train_loss = np.load(loss_path + \"yolov5_train_loss_40.np.npy\")\n",
    "val_loss = np.load(loss_path + \"yolov5_val_loss_40.np.npy\" )\n",
    "assert len(val_loss) == len(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single_losses = np.load(loss_path + \"yolov5_train_loss_single_41.np.npy\")\n",
    "val_single_losses = np.load(loss_path + \"yolov5_val_loss_single_41.np.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(loss_path + \"yolov5_general_test_results_40.pickle\",'rb')\n",
    "metrics_list = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "type(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\AppData\\Local\\Temp/ipykernel_5824/1522184988.py:12: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show(block=True)\n"
     ]
    }
   ],
   "source": [
    "x = [i for i in range(len(val_loss))]\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.plot(x,train_loss , label=\"Train Loss\", linewidth=3)\n",
    "plt.plot(x,val_loss, label=\"Validation Loss\", linewidth=3)\n",
    "plt.title(\"Train and Validation Loss for YOLOv5 pretraining on RSNA Pneumonia data\", fontsize=25)\n",
    "plt.ylabel(\"Loss\",fontsize=20)\n",
    "plt.xlabel(\"Epoch\",fontsize=20)\n",
    "plt.legend(shadow=True, prop={'size': 20})\n",
    "plt.xticks(fontsize=20 )\n",
    "plt.yticks(fontsize=20 )\n",
    "plt.show(block=True)\n",
    "fig.savefig(\"kp.jpg\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, ap, f1, ap_class, ap50, mp, mr, map50 = [], [], [], [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metrics in metrics_list:\n",
    "    precision.append(metrics[\"precision\"][0])\n",
    "    recall.append(metrics[\"recall\"][0])\n",
    "    ap.append(metrics[\"ap\"][0])\n",
    "    f1.append(metrics[\"f1\"][0])\n",
    "    ap_class.append(metrics[\"ap_class\"][0])\n",
    "    ap50.append(metrics[\"ap50\"][0])\n",
    "    mp.append(metrics[\"mp\"])\n",
    "    mr.append(metrics[\"mr\"])\n",
    "    map50.append(metrics[\"map50\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\AppData\\Local\\Temp/ipykernel_5824/1968311122.py:14: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show(block=True)\n"
     ]
    }
   ],
   "source": [
    "x = [i for i in range(len(map50))]\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.plot(x,map50 , label=\"map@50\", linewidth=3)\n",
    "plt.plot(x,mp, label=\"mean precision\", linewidth=3)\n",
    "plt.plot(x,mr, label=\"mean recall\", linewidth=3)\n",
    "plt.plot(x,f1, label=\"F1\", linewidth=3)\n",
    "plt.title(\"Selected metrics for YOLOv5 pretraining on RSNA Pneumonia data\", fontsize=25)\n",
    "plt.ylabel(\"metric\",fontsize=20)\n",
    "plt.xlabel(\"Epoch\",fontsize=20)\n",
    "plt.legend(shadow=True, prop={'size': 20})\n",
    "plt.xticks(fontsize=20 )\n",
    "plt.yticks(fontsize=20 )\n",
    "plt.show(block=True)\n",
    "path = \"../../imgs/models/metrics_giou_pretrained_yolo_40.png\"\n",
    "fig.savefig(\"kp2\",dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO training on SIIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_path = \"./losses_final_giou/\"\n",
    "train_loss = np.load(loss_path + \"yolov5_train_loss_39.np.npy\")\n",
    "val_loss = np.load(loss_path + \"yolov5_val_loss_39.np.npy\" )\n",
    "assert len(val_loss) == len(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(loss_path + \"yolov5_general_test_results_39.pickle\",'rb')\n",
    "metrics_list = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "type(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(len(val_loss))]\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.plot(x,train_loss , label=\"Train Loss\", linewidth=3)\n",
    "plt.plot(x,val_loss, label=\"Validation Loss\", linewidth=3)\n",
    "plt.title(\"Train and Validation Loss for YOLOv5 on SIIM-COVID19 data\", fontsize=25)\n",
    "plt.ylabel(\"Loss\",fontsize=20)\n",
    "plt.xlabel(\"Epoch\",fontsize=20)\n",
    "plt.legend(shadow=True, prop={'size': 20})\n",
    "plt.xticks(fontsize=20 )\n",
    "plt.yticks(fontsize=20 )\n",
    "plt.show(block=True)\n",
    "fig.savefig(\"../../imgs/models/loss_yolo_giou_40_siim.png\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, ap, f1, ap_class, ap50, mp, mr, map50 = [], [], [], [], [], [], [], [], []\n",
    "for metrics in metrics_list:\n",
    "    precision.append(metrics[\"precision\"][0])\n",
    "    recall.append(metrics[\"recall\"][0])\n",
    "    ap.append(metrics[\"ap\"][0])\n",
    "    f1.append(metrics[\"f1\"][0])\n",
    "    ap_class.append(metrics[\"ap_class\"][0])\n",
    "    ap50.append(metrics[\"ap50\"][0])\n",
    "    mp.append(metrics[\"mp\"])\n",
    "    mr.append(metrics[\"mr\"])\n",
    "    map50.append(metrics[\"map50\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(len(map50))]\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.plot(x,map50 , label=\"map@50\", linewidth=3)\n",
    "plt.plot(x,mp, label=\"mean precision\", linewidth=3)\n",
    "plt.plot(x,mr, label=\"mean recall\", linewidth=3)\n",
    "plt.plot(x,f1, label=\"F1\", linewidth=3)\n",
    "plt.title(\"Selected metrics for YOLOv5 on SIIM-COVID19 data\", fontsize=25)\n",
    "plt.ylabel(\"metric\",fontsize=20)\n",
    "plt.xlabel(\"Epoch\",fontsize=20)\n",
    "plt.legend(shadow=True, prop={'size': 20})\n",
    "plt.xticks(fontsize=20 )\n",
    "plt.yticks(fontsize=20 )\n",
    "plt.show(block=True)\n",
    "fig.savefig(\"../../imgs/models/metrics_yolo_30_siim.png\",dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.yolo import Model\n",
    "from utils.datasets import LoadImages, LoadImagesAndLabels\n",
    "from utils.general import check_img_size, non_max_suppression, scale_coords, xywhn2xyxy\n",
    "import matplotlib.patches as patches\n",
    "from dataset import ChestCocoDetection\n",
    "from torchvision import transforms\n",
    "import tkinter as tk\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 512\n",
    "CONFIDENCE_THRESHOLD = 0.01\n",
    "IOU_THRESHOLD = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "model = Model(cfg=\"yolo5l.yaml\",ch=3,nc=1)\n",
    "trained_weights = torch.load(\"./models_final_giou_10/yolov5_epoch_14.pt\")\n",
    "model.load_state_dict(trained_weights, strict=False)  # load\n",
    "model.eval()\n",
    "\n",
    "stride = int(model.stride.max())  # model stride\n",
    "img_size = check_img_size(IMAGE_SIZE, s=stride)  # check img_size\n",
    "print(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see sample predcition on one image in validation\n",
    "test_image_path = \"../../data/siim-covid19-detection/images/train/292c0aeda46d.png\"\n",
    "test_label_path = \"../../data/siim-covid19-detection/labels/train/292c0aeda46d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = LoadImages(test_image_path, img_size, stride)\n",
    "idx = np.random.randint(len(test))\n",
    "test_img = test.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bounding_boxes(target, ax):\n",
    "    boxes = target\n",
    "    for box in boxes:\n",
    "        mp_box = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1], edgecolor=\"r\", facecolor='none')\n",
    "        ax.add_patch(mp_box)\n",
    "\n",
    "def show_samples_for(test, train):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,8))\n",
    "    for im_i, (img, data) in enumerate([test, train]):\n",
    "        ax = axs[im_i] if isinstance(axs, np.ndarray) else axs\n",
    "        ax.set_title(f'Instance / Image Nr. {im_i + 1} / {2}')\n",
    "        plt.figure()\n",
    "        ax.imshow(img.permute(1,2,0), cmap=plt.cm.bone)\n",
    "        add_bounding_boxes(data, ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_det(boxes, labels, scores):\n",
    "    boxes = boxes.clip(0,1)\n",
    "\n",
    "    boxes_out = []\n",
    "    labels_out = []\n",
    "    scores_out = []\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        x1, y1, x2, y2 = box\n",
    "        if x1==x2 or y1==y2:\n",
    "            continue\n",
    "        box = [min(x1,x2), min(y1,y2), max(x1,x2), max(y1,y2)]\n",
    "        boxes_out.append(box)\n",
    "        labels_out.append(label)\n",
    "        scores_out.append(score)\n",
    "    return boxes_out, labels_out, scores_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = torch.tensor([[0.24809027777777778, 0.422244094488189 ,0.184375, 0.3059055118110236], [\n",
    "    0.7088541666666667 ,0.5190944881889764, 0.1482638888888889, 0.371259842519685\n",
    "]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, img, im0s, vid_cap in samples:\n",
    "    img_height, img_width = im0s.shape[0:2]\n",
    "    i_h = img.shape[1]\n",
    "    i_w = img.shape[2]\n",
    "    img = torch.from_numpy(img).float()\n",
    "    img /= 255.0\n",
    "    if img.ndimension() == 3:\n",
    "         img = img.unsqueeze(0)\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        prediction = model(img,augment=True)[0]\n",
    "        \n",
    "    prediction = non_max_suppression(prediction, CONFIDENCE_THRESHOLD, IOU_THRESHOLD, classes=None)\n",
    "    box = prediction[0][0][:4]\n",
    "    box = box.unsqueeze(0)\n",
    "    #for det in prediction:\n",
    "    #    if det is not None and len(det):\n",
    "     #       det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0s.shape).round()\n",
    "     #       det = det.data.cpu().numpy()\n",
    "   # print(f'det: {det}')\n",
    "\n",
    "    \n",
    "    # show results\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(10,8))\n",
    "    ax = axs[0] if isinstance(axs, np.ndarray) else axs\n",
    "    ax.set_title(f'Instance / Image Nr.')\n",
    "    plt.figure()\n",
    "    ax.imshow(img.detach().squeeze().permute(1,2,0), cmap=plt.cm.bone)\n",
    "    add_bounding_boxes(box, ax)\n",
    "    fig.savefig(\"smaple_yolo.png\")\n",
    "\n",
    "    \n",
    "    gt = xywhn2xyxy(gt,i_w,i_h)\n",
    "        \n",
    "        \n",
    "    fig, axs = plt.subplots(1, 1, figsize=(10,8))\n",
    "    ax = axs[0] if isinstance(axs, np.ndarray) else axs\n",
    "    ax.set_title(f'Instance / Image Nr.')\n",
    "    plt.figure()\n",
    "    ax.imshow(img.detach().squeeze().permute(1,2,0), cmap=plt.cm.bone)\n",
    "    add_bounding_boxes(gt, ax)\n",
    "    fig.savefig(\"smaple_gt.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

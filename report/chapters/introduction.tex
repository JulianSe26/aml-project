% !TEX root =  master.tex


\chapter{Introduction and problem definition}\label{chapter:intro}

\section*{Project Sources}
Research project on Github \url{https://github.com/JulianSe26/aml-project}.

\section{Kaeggle Challenge}
\sectionauthor{Written by Torben Krieger}
With the emergence of the COVID-19 disease caused by the SARS-CoV-2 virus late 2019 \autocite{huang2020clinical} and the evolution to a global pandemic within 2020 the demand of proper testing methods evolved. To stop the spread of the virus and keep the occupation of isolation beds within hospitals low it is critical that the used tests are fast and reliable. Reliability relates especially to a high sensitivity as false-negative tests could lead to unexpected infections due to personal behaviour or the treatment within hospitals \autocite{west2020covid}. Nowadays the usage of \ac{RT-PCR} tests is the general case and test kits as well as laboratory capacity is broadly available in most countries \autocite{vankasteren2020104412}. At the beginning of the pandemic the availability of tests kits was generally limited \autocite{Tannem1090}. In addition it was observed that the test result is highly dependent on the time of testing. According to studies there is a substantial number cases where only repeated tests after a couple of days revealed a COVID-19 infection \autocite{arevalo2020false}.

As addition to \ac{RT-PCR} several studies propose the usage of \ac{CT} scans of the chest for early and fast screening for a COVID-19 disease \autocite{fang2020sensitivity,xie2020chest}. For \ac{CT} scans the analysis time within laboratory could be avoided. At the same time a chest scan could provide early traces about the severity of the upcoming disease \autocite{yasin2020chest}. 

// todo from CT to CXR

Although the \citeauthor{acr2020recommendation} not recommends to use \ac{CT} or chest X-rays scans as first-line test \autocite{acr2020recommendation} the combination with an \ac{RT-PCR} test is might beneficially. Especially in cases where the initial \ac{RT-PCR} tests was negative, abnormalities found within a chest X-ray could endorse a second test at a later point of time. Thus the scans could help to detect false-negatives by \ac{RT-PCR} tests and avoid infections by keeping the suspicion for a COVID-19 disease. Several studies show that a detection of COVID-19 was earlier or only possible by chest X-ray or \ac{CT} scans \autocite{wang2020combination, tahamtan2020real}. However due to the exposure of radiation caused by any kind of X-ray scans the application of a COVID-19 detection by these scans is only acceptable for a concrete suspicion with symptoms. Thus the usage of X-rays for detection is prohibitive for preventive tests. 

// TODO: Was müssen wir überhaupt machen?


\section{Related Work}\sectionauthor{Written by Julian Seibel}
Exploring the possibilities of Computer Vision methods in medical image analysis reaches back to the late 90's where first proposals of \ac{CAD} systems were  introduced like in \autocite{kraus2000aluminium}, in which the authors detect aluminium dust-induced lung diseases.
With the rise of deep learning, medical image analysis on X-rays is subject of recent academic research reaching from detecting diseases like pneumonia \autocite{pneumoniaDetection} \autocite{pneumoniaDetection2} \autocite{gupta2019evolutionary} to tuberculosis and different thoracic diseases \autocite{jangam2021deep} and even pulmonary \autocite{vieira2021detecting}. Many of the contributions utilize a \ac{CNN} as single predictor. However there are interesting approaches using ensemble methods like in \autocite{livieris2019weighted}, where multiple predictors assigned with weights contribute to the final prediction. This stabilizes the training process and leads to a higher overall quality of the model by utilizing different advantages of different single models.

Even though it is not completely clear how a COVID-19 infection impacts the human body, it is possible to detect typical patterns in lungs using for example chest X-rays of affected patients. This opens many possibilities to provide fast and solid \ac{CAD} solutions while build on knowledge of previous works.
Since the pandemic started in 2020, there were many works published that deal with providing a reliable system for detecting COVID-19 infections using medical images. A \ac{CAD} based process would help the public health sector fighting the pandemic and would relieve medical personal in hospitals by increasing the automation of X-ray examination. Since this is of great importance for the society, several challenges were brought to life coming up with a wide variety of solutions. In the following, we will introduce some of them that we consider suitable for our approach.

The COVID-Net \autocite{wang2020covid} by \citeauthor{wang2020covid} uses a machine-driven exploration process to design a deep convolution learning model capable of classifying X-ray images of lungs into three categories (normal, pneumonia, COVID-19). The results of their study look promising and although the authors stated explicitly the non-production-ready state, the work can be used as a basis for future projects.

Another work using a deep neural network is the proposed CovidAID \autocite{mangal2020covidaid} network by \citeauthor{mangal2020covidaid}. In their approach, they use a pre-trained CheXNet \autocite{rajpurkar2017chexnet} \ac{CNN} while substituting the output layer of the model to fit it to their needs of predicting one of the four classes (normal, bacterial pneumonia, viral pneumonia, COVID-19). The authors applied transfer learning by only actively apply the train algorithm to the final layers of their proposed model, whereas the backbone weights are frozen.
In their final comparison, the authors reported to significantly improve upon the results on the previous introduced COVID-Net.
Similar to this, in the proposed method \autocite{CoronaDLTransfer} by \citeauthor{CoronaDLTransfer} transformation learning is applied to fine-tune and compare three state-of-the-art models (Inception ResNetV2, InceptionNetV3 and NASNetLarge) to detect COVID-19 infections, non-COVID-19 infections (like pneumonia) and no infection. Despite the high accuracy of 99\% achieved by the InceptionNetV3 model, the authors reported that all models suffer from overfitting due to limited amount of available data.

Since we are participating in the previously described challenge, we have a fixed requirement in terms of predicting not only if a X-ray image is COVID-19 positive, we rather need to detect and locate suspicious areas in such images. There exist a handful of related works we selected that try to achieve a similar goal, namely \autocite{brunese2020explainable}, \autocite{fan2020inf} and \autocite{al2021fast}.

Regarding the first, \citeauthor{brunese2020explainable} \autocite{brunese2020explainable} introduce a composed approach consisting of three different phases. In the first phase a image is classified as \enquote{potentially positive} by predicting if there is pneumonia patterns present in the image. The second phase then tries to differ the finding into COVID-19 caused or just pneumonia. In their last step, the authors designed a process using Gradient-weighted Class Activation Mapping to localize the affected areas that are symptomatic of a COVID-19 presence. With this approach the authors are able to add some explainability to their model by providing visually which areas are important for the final decision of the network.\newline
The second approach by \citeauthor{fan2020inf} \autocite{fan2020inf} proposed a model called Lung Infection Segmentation Deep Network (Inf-Net) that is capable of identifying and segmenting suspicious regions typical for COVID-19 infections. They use a partial decoder approach to generate a global representation of segmented maps followed by a implicit reverse attention and explicit edge attention mechanism to enhance the map boundaries. Due to the limitation of available data, the authors proposed a semi-supervised framework for training the model.\newline
The last approach by \citeauthor{al2021fast} \autocite{al2021fast} a \ac{YOLO} object detection model \autocite{yoloOriginal} is used to detect and diagnose COVID-19, being also capable of differentiating it from eight other respiratory diseases. In contrast to the former approach, the proposed \ac{CAD} system using the \ac{YOLO} model classifies and predicts bounding boxes for regions of interest. In their paper, the authors reported a diagnostic accuracy of 97.40\%.

Ein R-CNN Paper vlt noch referencen? \autocite{podder_efficient_2021}




\section{Proposed Solution}
\sectionauthor{Written by Tobias Richstein}

To tackle the described Kaeggle Challenge, we propose a multi-faceted approach to the solution. Other works in this field have shown that using \acp{CNN} can be a viable strategy to detect a multitude of illnesses in X-ray images and in some cases also locate them. Another approach described above is to just classify the image but not to provide bounding boxes. In accordance with the Kaeggle challenge, we need to classify the given X-ray images and provide bounding boxes for suspicious areas, by means of object detection, that might be indicators of a COVID-19 pneumonia.

Object detection in images is largely dominated by four network architectures: RetinaNet \autocite{lin_focal_2018}, Single Shot MultiBox Detector \autocite{liu_ssd_2016}, \acl{R-CNN} \autocite{girshick_rich_2014} and \ac{YOLO} \autocite{yoloOriginal}. As shown in the Related Work section, the latter two have been shown to be suitable for the task at hand in \autocite{podder_efficient_2021} or \autocite{al2021fast} respectively which is why we decided to also focus on these two architectures for our object detection solution at the image level. We use a Faster \acs{R-CNN} with a ResNeXt backbone that we pretrain on the NIH-dataset as well as a \acs{YOLO} network whose backbone is pretrained on the RSNA dataset. Pre-training the backbone helps the actual detector because the feature vectors that the backbone generates are situated within the actual problem domain instead of being generalized towards a dataset like ImageNet. The actual training for the object detection of opacities is done on the dataset of the Kaeggle challenge. We use an ensemble box fusion to combine the bounding boxes of both networks to generate more accurate results and achieve respectable results on a held out validation set at the image level.

At the study level which consists of one or more images of a patient we employ a classification network which reuses the same ResNeXt backbone as the Faster \ac{R-CNN} to draw conclusions about whether a patient study shall be looked at as COVID-19 positive. \textbf{ELABORATE MORE}

To make the solution a bit more approachable and also allow some hands-on experience for users not necessarily familiar with how to run inference on their own, we built a prototype web-app to which images can be uploaded and the different models can be tested. It allows users to see the predictions of each model, image and study level, and also how the box fusion boosts the detection accuracy. 

The datasets we use and why we use them is described in the next section \vref{chapter:data} and our model approaches are detailed in section \vref{chapter:detection}. Later on we evaluate our approach in section \vref{chapter:evaluation} and describe the web-app in section \vref{chapter:webapp} before coming to a conclusion later in section \vref{chapter:conclusion}.
% !TEX root =  master.tex
\chapter{Conclusion}\label{chapter:conclusion}
\chapterauthor{Written by All}


Future outlook and research topics /improvements:

more data (as always), E2E training for detection ensemble, explore more models (Mask R-CNN...), providing ablation studies of how pretrained weights contribute to the overall scores.

vlt noch kritik an ML approaches f√ºr Corona:
 \begin{itemize}
 	\item \url{https://www.heise.de/hintergrund/Warum-KI-Werkzeuge-gegen-COVID-19-bislang-versagt-haben-6158061.html}
 	\item \url{https://www.turing.ac.uk/sites/default/files/2021-06/data-science-and-ai-in-the-age-of-covid_full-report_2.pdf}
 	\item \url{https://doi.org/10.1136/bmj.m1328}
 \end{itemize}

In this report we have talked a lot about how different machine learning methods, and in this case computer vision, can help combat the pandemic. Honorably ML researchers and doctors all around the world scrambled to try and help at the start and during the pandemic by providing datasets, studies and models concerning all facets of what to do against the virus, for the infected or for society as a whole. Recently though, doubts have been cast on these efforts, as some studies suggest that machine learning models might not be very effective or in the worst case even dangerous. In a large scale meta study, published in the British Medical Journal, \citeauthor{wynants_prediction_2020} analyze 232 models proposed in 169 studies and find that not a single one is suitable for clinical use but that at least two might be promising with more work \autocite{wynants_prediction_2020}. Another study by \citeauthor{aix-covnet_common_2021} that closely examines 62 studies regarding the topic that we were also working on of identifying COVID-19 infections in patients, comes to the same conclusion that none of them are suitable for clinical use \autocite{aix-covnet_common_2021}. These concerns show that while there has been great effort and a lot of good will in the research community, the processes and studies are not yet as matured as maybe ML researchers and practitioners would like. While most times no harm is done in other areas of ML usage when an error is made, the stakes in the medical field are a lot higher and therefore a lot more care has to be put into every study and ML model that is proposed. 
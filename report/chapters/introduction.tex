% !TEX root =  master.tex


\chapter{Introduction and problem definition}\label{chapter:intro}

\section*{Project Sources}
Research project on Github \url{https://github.com/JulianSe26/aml-project}.

\section{Kaggle Challenge}\label{sec:kaggle}
\sectionauthor{Written by Torben Krieger}
With the emergence of the COVID-19 disease caused by the SARS-CoV-2 virus in late 2019 \autocite{huang2020clinical} and the evolution to a global pandemic in 2020, the demand for proper testing methods rose quickly. To stop the spread of the virus and to keep isolation bed occupancy in hospitals low, it is critical that the tests used are fast and reliable. Reliability relates especially to a high sensitivity as false-negative tests could lead to unexpected infections due to personal behavior or the treatment received in hospitals \autocite{west2020covid}. Nowadays \ac{RT-PCR} tests are mostly used to detect and confirm infections and test kits as well as laboratory capacity is broadly available in most countries \autocite{vankasteren2020104412} which was not generally the case at the start of the pandemic \autocite{Tannem1090}. Additionally it was observed that the test result is highly dependent on the time of testing. According to studies there is a substantial number of cases where only repeated testing in a span of multiple days revealed a COVID-19 infection \autocite{arevalo2020false}.

In addition to \ac{RT-PCR} testing, several studies propose the usage of \ac{CT} or normal \acf{CXR} scans for early and fast screening of a COVID-19 infection \autocite{fang2020sensitivity,xie2020chest}. Using these scans, the long laboratory analysis time could be avoided. At the same time a \acs{CXR} scan could provide early hints about the severity of the upcoming disease \autocite{yasin2020chest}. 

Although the \citeauthor{acr2020recommendation} does not recommend the use of \ac{CT} or \ac{CXR} scans as first-line tests \autocite{acr2020recommendation}, the combination with \ac{RT-PCR} tests might be beneficial. Especially in cases where the initial \ac{RT-PCR} test was negative, abnormalities found on a \acs{CXR} could endorse a second test at a later point in time. Thus the scans could help in detecting false-negatives by \ac{RT-PCR} tests and avoid infections by keeping the suspicion of a COVID-19 infection. Several studies show that COVID-19 detection is possible through \ac{CXR} or \ac{CT} scans even when an \ac{RT-PCR} test might still be negative due to low viral load \autocite{wang2020combination, tahamtan2020real}. However due to the exposure to radiation caused by any kind of X-ray scan, they should only be done when there is sufficient evidence of a COVID-19 infection. Thus the usage of \ac{CXR} for detection is unfeasible for preventive tests.

Generally abnormalities indicating a potential COVID-19 infection, so called \textit{opacities} can be found more easily using a CT scanner compared to normal \ac{CXR} \autocite{jacobi2020portable}. But because normal X-Ray machines are cheaper, they are more widespread in poorer countries and rural regions. Additionally the screening is faster and simpler, there is less exposure to radiation and the decontamination is easier.

In this project we want to analyze possibilities of how to detect a COVID-19 infection on \ac{CXR} images automatically using machine learning methods. For reference we will use the \enquote{\textit{SIIM-FISABIO-RSNA COVID-19 Detection}} Kaggle Challenge \autocite{SIIMKaggle} in which competitors are asked to perform object detection to identify COVID-19 typical opacities on \ac{CXR} images and mark them using bounding boxes. Additionally a classification on the whole image for a COVID-19 infection should be done.
The challenge provides training data with labels and ground-truth boxes and test data without any ground truth annotations. Any submission is rated using the held out test set. The images within the dataset are provided in the original DICOM format in which they were saved by the used modalities. Each image belongs to a study, which relates to a single scrutiny done for a patient. A single study may contain multiple images. The dataset contains samples that may or may not be COVID-19 positive but also for pneumonia caused by other diseases. More details about the used dataset can be found in section \vref{data:siim}.

Precisely the Kaggle challenge defines following two tasks:

\begin{description}
    \item[Image-level] Perform \textit{object detection} to detect lung opacities for each chest radiograph image provided. As the result a bounding box should be predicted if an opacity was found. There is only a single object class (\texttt{opacity}) to be predicted. A single image can contain multiple opacities.
    \item[Study-level] Predict a potential COVID-19 infection for a given study by classifying the input into four different classes (see below). As the prediction should be done on study level, multiple images may have to be analyzed for a single classification. Although the initial challenge description denotes that multiple labels per image are possible, other sources indicate that the label categories are mutually exclusive \autocite{litmanovich2020review, SIIMKaggleAnnotation}. Thus, this task qualifies as \textit{multi-class classification}.
\end{description}

It is not required that the study-level task uses the result of the image-level task as its input or the other way around. The challenge only requires that the results are predicted for both.

Possible classes for the study level task are:

\begin{itemize}
    \item Negative for Pneumonia
    \item Typical Appearance
    \item Indeterminate Appearance
    \item Atypical Appearance
\end{itemize}

Where the class \textit{Negative for Pneumonia} means that no COVID-19 or non-COVID-19 pneumonia was detected. Contrary \textit{Indeterminate Appearance} means that there are findings for a pneumonia but the findings are not in line with the characteristics of COVID-19. The label \textit{Atypical Appearance} means that there were findings which are atypical or uncommon for COVID-19. Finally \textit{Typical Appearance} means thatthe findings are typical for COVID-19, however other causes are still possible.

The Challenge is a so called \textit{Code Competition}. That means that competitors are asked to submit their solution as Python Notebook, not as a single submission file. The notebook is then executed on cloud services provided by Kaggle. The single notebook has to prepare the data, execute the training of the models and finally create a submission file. Per submission there are limits for the total allowed runtime of the notebook. For the referenced challenge the CPU and GPU time is limited to 9 hours each \autocite{SIIMKaggle}. Additionally no internet access is possible within the execution environment. However publicly available packages and pre-trained models are allowed and accessible. The notebook has to create a single submission file which contains both the predicted labels for the image- and study-level task. Each record is identified using either the DICOM study or image id. The file has to be formatted as CSV. Results of the classification task are represented as bounding boxes with the size of a single pixel and a confidence of 1. For the official rating of the predicted bounding boxes the \ac{mAP} metric with an \ac{IoU} of \num{0.5} is used.

Multiple organisations joined up for hosting the challenge and providing the data, namely the \textit{Foundation for the Promotion of Health and Biomedical Research of Valencia Region} (FISABIO), the \textit{Medical Imaging Databank of the Valencia Region} (BIMCV), the \textit{Radiological Society of North America} (RSNA) and the initiator of the challenge the \textit{Society for Imaging Informatics in Medicine} (SIIM). The official competition ended on August 10, 2021, but late submissions are possible even though the winners were already announced.

For this project we decided to take the Kaggle Challenge as a reference but not to do a (late-)submission. This means that we want to solve both tasks and conduct a validation of our results but do not intend to create a single notebook nor to create a complete submission file in the correct format. 


\section{Related Work}\sectionauthor{Written by Julian Seibel}
Exploring the possibilities of Computer Vision methods in medical image analysis reaches back to the late 1990s where first proposals of \ac{CAD} systems were introduced like in \autocite{kraus2000aluminium}, where the authors detect aluminium dust-induced lung diseases.
With the rise of deep learning, medical image analysis on \acp{CXR} became an important subject of recent academic research reaching from detecting diseases like pneumonia \autocite{pneumoniaDetection, pneumoniaDetection2, gupta2019evolutionary} to tuberculosis and other thoracic or pulmonary illnesses \autocite{jangam2021deep, vieira2021detecting}. Many of the contributions utilize a \ac{CNN} as a single predictor. However there are interesting approaches that use ensemble methods like in \autocite{livieris2019weighted}, where multiple predictors assigned with different weights contribute to the final prediction. This stabilizes the training process and leads to a higher overall quality of the model by utilizing different advantages of several distinct models.

Even though it is not completely clear in which ways a COVID-19 infection impacts the human body, it is possible to detect typical patterns in lungs using for example chest X-rays of affected patients. This opens many possibilities to provide fast and solid \ac{CAD} solutions while build on the knowledge of previous works.
Since the pandemic started in late 2019, there were many works published that deal with providing a reliable system for detecting COVID-19 infections using medical images. A \ac{CAD} based process would help the public health sector to fight the pandemic and would relieve medical personnel in hospitals by increasing the automation of \ac{CXR} examination. Since this is of great importance for society, several works were published coming up with a wide variety of solutions. In the following, we will introduce some of the ones that we consider suitable for our approach.

The \textit{COVID-Net} \autocite{wang2020covid} by \citeauthor{wang2020covid} uses a machine-driven exploration process to design a deep convolution learning model capable of classifying \ac{CXR} images of lungs into three categories (normal, pneumonia, COVID-19). The results of their study look promising and although the authors stated explicitly the non-production-ready state, the work can be used as a basis for future projects.

Another work using a deep neural network is the proposed \textit{CovidAID} \autocite{mangal2020covidaid} network by \citeauthor{mangal2020covidaid}. In their approach, they use a pre-trained \textit{CheXNet} \autocite{rajpurkar2017chexnet} \ac{CNN} while substituting the output layer of the model to fit it to their requirement of predicting one of the four classes (normal, bacterial pneumonia, viral pneumonia, COVID-19). The authors applied transfer learning by only actively training the final layers of their proposed model, whereas the backbone weights are frozen.
In their final comparison, the authors reported a significant improvement upon the results of the previously introduced COVID-Net.
Similar to this, in the proposed method \autocite{CoronaDLTransfer} by \citeauthor{CoronaDLTransfer} transformation learning is applied to fine-tune and compare three state-of-the-art models (Inception ResNetV2, InceptionNetV3 and NASNetLarge) to detect COVID-19 infections, non-COVID-19 infections (like pneumonia) and no infection. Despite the high accuracy of 99\% achieved by the InceptionNetV3 model, the authors reported that all models suffer from overfitting due to a limited amount of available data.

Since we are participating in the previously described challenge, we have a fixed requirement in terms of predicting not only if a \ac{CXR} image is COVID-19 positive, but we rather need to detect and locate suspicious areas in such images. There exist a handful of related works we selected that try to achieve a similar goal, namely \autocite{brunese2020explainable, fan2020inf} and \autocite{al2021fast}.

Regarding the first, \citeauthor{brunese2020explainable} \autocite{brunese2020explainable} introduce a composed approach consisting of three different phases. In the first phase an image is classified as \enquote{potentially positive} by predicting whether there are pneumonia patterns present in the image. The second phase then tries to differentiate the finding into COVID-19 caused or pneumonia. In their last step, the authors designed a process using Gradient-weighted Class Activation Mapping to localize the affected areas that are symptomatic of COVID-19. With this approach the authors are able to add some explainability to their model by providing visualizations of areas important to the final decision of the network.\newline
The second approach by \citeauthor{fan2020inf} \autocite{fan2020inf} proposes a model called Lung Infection Segmentation Deep Network (\textit{Inf-Net}) that is capable of identifying and segmenting suspicious regions typical for COVID-19 infections. They use a partial decoder approach to generate a global representation of segmented maps followed by an implicit reverse attention and explicit edge attention mechanism to enhance the map boundaries. Due to limited available data, the authors propose a semi-supervised framework for training the model.\newline
In the last approach by \citeauthor{al2021fast} \autocite{al2021fast} a \textit{\ac{YOLO}} object detection model \autocite{yoloOriginal} is used to detect and diagnose COVID-19, with the model also being capable of differentiating it from eight other respiratory diseases. In contrast to the previous approach, the proposed \ac{CAD} system uses the \ac{YOLO} model to classify and predict bounding boxes for regions of interest. In their paper, the authors report a diagnostic accuracy of $97.40\%$.
Going a step further, \citeauthor{podder_efficient_2021} use a mask based prediction model (\textit{Mask \ac{R-CNN}}) to train and test a classifier that distinguishes between patients infected and not infected with COVID-19. In this paper, the authors achieve an accuracy of $96.6\%$ evidencing the huge potential of Mask \ac{R-CNN} as a suitable model candidate \autocite{podder_efficient_2021}.




\section{Proposed Solution}
\sectionauthor{Written by Tobias Richstein}

To tackle the described Kaggle Challenge, we propose a multi-faceted approach to the solution. Other works in this field have shown that using \acp{CNN} can be a viable strategy to detect a multitude of illnesses in X-ray images and in some cases also locate them. Another approach described above is to just classify the image but not to provide bounding boxes. In accordance with the Kaggle challenge, we need to classify the given X-ray images and provide bounding boxes for suspicious areas, by means of object detection, that might be indicators of a COVID-19 pneumonia.

Object detection in images is largely dominated by four network architectures: RetinaNet \autocite{lin_focal_2018}, Single Shot MultiBox Detector \autocite{liu_ssd_2016}, \acl{R-CNN} \autocite{girshick_rich_2014} and \ac{YOLO} \autocite{yoloOriginal}. As shown in the Related Work section, the latter two have been shown to be suitable for the task at hand in \autocite{podder_efficient_2021} or \autocite{al2021fast} respectively which is why we decided to also focus on these two architectures for our object detection solution at the image level. We use a Faster \acs{R-CNN} with a ResNeXt backbone that we pre-train on the NIH-dataset as well as a \acs{YOLO} network whose backbone is pre-trained on the RSNA dataset. Pre-training the backbone helps the actual detector because the feature vectors that the backbone generates are situated within the actual problem domain instead of being generalized towards a dataset like ImageNet. The actual training for the object detection of opacities is done on the dataset of the Kaggle challenge. We use an ensemble box fusion to combine the bounding boxes of both networks to generate more accurate results and achieve respectable results on a held out validation set at the image level.

At the study level which consists of one or more images of a patient we employ a classification network which reuses the same ResNeXt backbone as the Faster \ac{R-CNN} to draw conclusions about whether a patient study shall be looked at as COVID-19 positive or not.

To make the solution a bit more approachable and also allow some hands-on experience for users not necessarily familiar with how to run inference on their own, we built a prototype web-app to which images can be uploaded and the different models can be tested. It allows users to see the predictions of each model, image and study level, and also how the box fusion boosts the detection accuracy. 

The datasets we use and why we use them is described in the next section \vref{chapter:data} and our model approaches are detailed in section \vref{chapter:detection}. Later on we evaluate our approach in section \vref{chapter:evaluation} and describe the web-app in section \vref{chapter:webapp} before coming to a conclusion later in section \vref{chapter:conclusion}.
% !TEX root =  master.tex


\chapter{Introduction and problem definition}\label{chapter:intro}

\section*{Project Sources}
Research project on Github \url{https://github.com/JulianSe26/aml-project}.

\section{Kaeggle Challenge}\label{sec:kaggle}
\sectionauthor{Written by Torben Krieger}
With the emergence of the COVID-19 disease caused by the SARS-CoV-2 virus late 2019 \autocite{huang2020clinical} and the evolution to a global pandemic within 2020 the demand of proper testing methods evolved. To stop the spread of the virus and keep the occupation of isolation beds within hospitals low it is critical that the used tests are fast and reliable. Reliability relates especially to a high sensitivity as false-negative tests could lead to unexpected infections due to personal behaviour or the treatment within hospitals \autocite{west2020covid}. Nowadays the usage of \ac{RT-PCR} tests is the general case and test kits as well as laboratory capacity is broadly available in most countries \autocite{vankasteren2020104412}. At the beginning of the pandemic the availability of tests kits was generally limited \autocite{Tannem1090}. In addition it was observed that the test result is highly dependent on the time of testing. According to studies there is a substantial number cases where only repeated tests after a couple of days revealed a COVID-19 infection \autocite{arevalo2020false}.

As addition to \ac{RT-PCR} several studies propose the usage of \ac{CT} or normal X-Ray scans of the chest for early and fast screening for a COVID-19 disease \autocite{fang2020sensitivity,xie2020chest}. For these scans the analysis time within laboratory could be avoided. At the same time a chest scan could provide early traces about the severity of the upcoming disease \autocite{yasin2020chest}. 

Although the \citeauthor{acr2020recommendation} not recommends to use \ac{CT} or chest X-rays scans as first-line test \autocite{acr2020recommendation} the combination with an \ac{RT-PCR} test is might beneficial. Especially in cases where the initial \ac{RT-PCR} tests was negative, abnormalities found within a chest X-ray could endorse a second test at a later point of time. Thus the scans could help to detect false-negatives by \ac{RT-PCR} tests and avoid infections by keeping the suspicion for a COVID-19 disease. Several studies show that a detection of COVID-19 was earlier or only possible by chest X-ray or \ac{CT} scans \autocite{wang2020combination, tahamtan2020real}. However due to the exposure of radiation caused by any kind of X-ray scans the application of a COVID-19 detection by these scans is only acceptable for a concrete suspicion with symptoms. Thus the usage of X-rays for detection is prohibitive for preventive tests.

Generally abnormalities indicating a potential COVID-19 disease, so called \textit{opacities} could be found more easily using a CT scanner compared to normal X-Rays \autocite{jacobi2020portable}. However normal X-Ray modalities are less expensive thus better available also within development countries. Additionally the screening is faster and simpler, the radiation exposure is less and the decontamination is easier.

Within this project we want to analyse the possibilities to detect a COVID-19 disease on \ac{CXR} images automatically using machine learning methods. As reference we will use the \enquote{\textit{SIIM-FISABIO-RSNA COVID-19 Detection}} Kaggle Challenge \autocite{SIIMKaggle}. Within this challenge competitors are ask to perform object detection to identify COVID-19 typical opacities on chest X-Ray images and mark them using bounding boxes. Second a classification for a COVID-19 disease should be done.
The challenge provides train data with labels and ground-truth boxes and test data without ground truth. Any submission is rated using the held back test ground truth. The images within the dataset are provided in the original DICOM format written by the used modalities. Each image belongs to a study, which relates to a single scrutiny done for a patient. A single study may contains multiple images. The dataset contains samples with or without a COVID-19 disease but also for pneumonia caused by other diseases. More details about used dataset could be found in section \ref{data:siim}.

Precisely the Kaggle challenge defines following two tasks:

\begin{description}
    \item[Image-level] Perform \textit{object detection} to detect opacities within the lung for each chest radiograph image provided. As result a bounding box should be predicted if an opacity was found. There is only a single object class (\texttt{opacity}) to be predicted. A single image could contain multiple opacities.
    \item[Study-level] Predict a potential COVID-19 disease for a given study by classifying in four different classes (see below). As the prediction should be done on study level, might multiple images have to be analysed for a single classification. Although the initial challenge description denotes that multiple labels per image are possible other sources indicate that the label categories are mutual exclusive \autocite{litmanovich2020review, SIIMKaggleAnnotation}. Thus this task qualifies as \textit{multi-class classification}.
\end{description}

It is not required that the study-level task uses the result of the image-level task as input or the other way around. The challenge only requires that the results are predicted for both.

Possible classes for the study level task are:

\begin{itemize}
    \item Negative for Pneumonia,
    \item Typical Appearance,
    \item Indeterminate Appearance,
    \item Atypical Appearance.
\end{itemize}

Where the class \textit{Negative for Pneumonia} means that no COVID or non-COVID pneumonia was detected. Contrary \textit{Indeterminate Appearance} means that there are findings for a pneumonia but the findings are not characteristic for COVID-19. The label \textit{Atypical Appearance} means that there were findings which are atypical or uncommon for COVID-19. Finally \textit{Typical Appearence} means that found findings are typical for COVID-19, however other causes are still possible.

The Challenge is a so called \textit{Code Competition}. That means competitors are asked to submit their solution as Python Notebook, not as single submission file. The notebook is then executed on cloud services provided by Kaggle. The single notebook has to prepare the data, execute the training of the models and finally create a submission file. Per submission there are limits for the total allowed runtime of the notebook. For the referenced challenge the CPU and GPU time is limited to 9 hours each \autocite{SIIMKaggle}. Additionally no internet access is possible within the execution environment. However publicly available packages and pre-trained models are allowed and accessible. The notebook has to create a single submission file which contains both the predicted labels for the image- and study-level task. Each record is identified using either the DICOM study or image id. The file has to be formatted as CSV. Results of the classification task are represented as bounding box with the size of a single pixel and a confidence of 1. For the official rating of the predicted bounding boxes a \ac{mAP} with an \ac{IoU} of 0.5 is used.

Multiple organisations joined up for hosting the challenge and providing the data, namely the \textit{Foundation for the Promotion of Health and Biomedical Research of Valencia Region} (FISABIO), the \textit{Medical Imaging Databank of the Valencia Region} (BIMCV), the \textit{Radiological Society of North America} (RSNA) and as initial initiator of the challenge the \textit{Society for Imaging Informatics in Medicine} (SIIM). The official competition ended on August 10, 2021, still late submissions are possible but the winners are already announced.

For this project we decided to take the Kaggle Challenge rather as reference but do not do a (late-)submission. This means we want to solve both tasks and conduct a validation of our results but do not intend to create a single notebook nor creating a complete submission file in the correct format. 


\section{Related Work}\sectionauthor{Written by Julian Seibel}
Exploring the possibilities of Computer Vision methods in medical image analysis reaches back to the late 90's where first proposals of \ac{CAD} systems were  introduced like in \autocite{kraus2000aluminium}, in which the authors detect aluminium dust-induced lung diseases.
With the rise of deep learning, medical image analysis on X-rays is subject of recent academic research reaching from detecting diseases like pneumonia \autocite{pneumoniaDetection} \autocite{pneumoniaDetection2} \autocite{gupta2019evolutionary} to tuberculosis and different thoracic diseases \autocite{jangam2021deep} and even pulmonary \autocite{vieira2021detecting}. Many of the contributions utilize a \ac{CNN} as single predictor. However there are interesting approaches using ensemble methods like in \autocite{livieris2019weighted}, where multiple predictors assigned with weights contribute to the final prediction. This stabilizes the training process and leads to a higher overall quality of the model by utilizing different advantages of different single models.

Even though it is not completely clear how a COVID-19 infection impacts the human body, it is possible to detect typical patterns in lungs using for example chest X-rays of affected patients. This opens many possibilities to provide fast and solid \ac{CAD} solutions while build on knowledge of previous works.
Since the pandemic started in late 2019, there were many works published that deal with providing a reliable system for detecting COVID-19 infections using medical images. A \ac{CAD} based process would help the public health sector fighting the pandemic and would relieve medical personal in hospitals by increasing the automation of X-ray examination. Since this is of great importance for the society, several challenges were brought to life coming up with a wide variety of solutions. In the following, we will introduce some of them that we consider suitable for our approach.

The COVID-Net \autocite{wang2020covid} by \citeauthor{wang2020covid} uses a machine-driven exploration process to design a deep convolution learning model capable of classifying X-ray images of lungs into three categories (normal, pneumonia, COVID-19). The results of their study look promising and although the authors stated explicitly the non-production-ready state, the work can be used as a basis for future projects.

Another work using a deep neural network is the proposed CovidAID \autocite{mangal2020covidaid} network by \citeauthor{mangal2020covidaid}. In their approach, they use a pre-trained CheXNet \autocite{rajpurkar2017chexnet} \ac{CNN} while substituting the output layer of the model to fit it to their needs of predicting one of the four classes (normal, bacterial pneumonia, viral pneumonia, COVID-19). The authors applied transfer learning by only actively apply the train algorithm to the final layers of their proposed model, whereas the backbone weights are frozen.
In their final comparison, the authors reported to significantly improve upon the results on the previous introduced COVID-Net.
Similar to this, in the proposed method \autocite{CoronaDLTransfer} by \citeauthor{CoronaDLTransfer} transformation learning is applied to fine-tune and compare three state-of-the-art models (Inception ResNetV2, InceptionNetV3 and NASNetLarge) to detect COVID-19 infections, non-COVID-19 infections (like pneumonia) and no infection. Despite the high accuracy of 99\% achieved by the InceptionNetV3 model, the authors reported that all models suffer from overfitting due to limited amount of available data.

Since we are participating in the previously described challenge, we have a fixed requirement in terms of predicting not only if a X-ray image is COVID-19 positive, we rather need to detect and locate suspicious areas in such images. There exist a handful of related works we selected that try to achieve a similar goal, namely \autocite{brunese2020explainable}, \autocite{fan2020inf} and \autocite{al2021fast}.

Regarding the first, \citeauthor{brunese2020explainable} \autocite{brunese2020explainable} introduce a composed approach consisting of three different phases. In the first phase a image is classified as \enquote{potentially positive} by predicting if there is pneumonia patterns present in the image. The second phase then tries to differ the finding into COVID-19 caused or just pneumonia. In their last step, the authors designed a process using Gradient-weighted Class Activation Mapping to localize the affected areas that are symptomatic of a COVID-19 presence. With this approach the authors are able to add some explainability to their model by providing visually which areas are important for the final decision of the network.\newline
The second approach by \citeauthor{fan2020inf} \autocite{fan2020inf} proposed a model called Lung Infection Segmentation Deep Network (Inf-Net) that is capable of identifying and segmenting suspicious regions typical for COVID-19 infections. They use a partial decoder approach to generate a global representation of segmented maps followed by a implicit reverse attention and explicit edge attention mechanism to enhance the map boundaries. Due to the limitation of available data, the authors proposed a semi-supervised framework for training the model.\newline
The last approach by \citeauthor{al2021fast} \autocite{al2021fast} a \ac{YOLO} object detection model \autocite{yoloOriginal} is used to detect and diagnose COVID-19, being also capable of differentiating it from eight other respiratory diseases. In contrast to the former approach, the proposed \ac{CAD} system using the \ac{YOLO} model classifies and predicts bounding boxes for regions of interest. In their paper, the authors reported a diagnostic accuracy of $97.40\%$.
Going a step further, \citeauthor{podder_efficient_2021} uses a mask based prediction model (mask R-CNN) to train and test a classifier that distinguishes between patients infected and non-infected with COVID-19. Also here, the authors achieved a accuracy of $96.6\%$ evidencing the huge potential of mask R-CNN as a suitable model candidate \autocite{podder_efficient_2021}.




\section{Proposed Solution}
\sectionauthor{Written by Tobias Richstein}

To tackle the described Kaeggle Challenge, we propose a multi-faceted approach to the solution. Other works in this field have shown that using \acp{CNN} can be a viable strategy to detect a multitude of illnesses in X-ray images and in some cases also locate them. Another approach described above is to just classify the image but not to provide bounding boxes. In accordance with the Kaeggle challenge, we need to classify the given X-ray images and provide bounding boxes for suspicious areas, by means of object detection, that might be indicators of a COVID-19 pneumonia.

Object detection in images is largely dominated by four network architectures: RetinaNet \autocite{lin_focal_2018}, Single Shot MultiBox Detector \autocite{liu_ssd_2016}, \acl{R-CNN} \autocite{girshick_rich_2014} and \ac{YOLO} \autocite{yoloOriginal}. As shown in the Related Work section, the latter two have been shown to be suitable for the task at hand in \autocite{podder_efficient_2021} or \autocite{al2021fast} respectively which is why we decided to also focus on these two architectures for our object detection solution at the image level. We use a Faster \acs{R-CNN} with a ResNeXt backbone that we pretrain on the NIH-dataset as well as a \acs{YOLO} network whose backbone is pretrained on the RSNA dataset. Pre-training the backbone helps the actual detector because the feature vectors that the backbone generates are situated within the actual problem domain instead of being generalized towards a dataset like ImageNet. The actual training for the object detection of opacities is done on the dataset of the Kaeggle challenge. We use an ensemble box fusion to combine the bounding boxes of both networks to generate more accurate results and achieve respectable results on a held out validation set at the image level.

At the study level which consists of one or more images of a patient we employ a classification network which reuses the same ResNeXt backbone as the Faster \ac{R-CNN} to draw conclusions about whether a patient study shall be looked at as COVID-19 positive. \textbf{ELABORATE MORE}

To make the solution a bit more approachable and also allow some hands-on experience for users not necessarily familiar with how to run inference on their own, we built a prototype web-app to which images can be uploaded and the different models can be tested. It allows users to see the predictions of each model, image and study level, and also how the box fusion boosts the detection accuracy. 

The datasets we use and why we use them is described in the next section \vref{chapter:data} and our model approaches are detailed in section \vref{chapter:detection}. Later on we evaluate our approach in section \vref{chapter:evaluation} and describe the web-app in section \vref{chapter:webapp} before coming to a conclusion later in section \vref{chapter:conclusion}.